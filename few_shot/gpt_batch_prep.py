import cv2, base64, os, argparse, json, threading, math, time, random
from concurrent.futures import ThreadPoolExecutor, as_completed
from google.cloud import storage
from openai import OpenAI
from tqdm import tqdm
import numpy as np

MAX_FRAMES = 100
NUM_ATTEMPTS = 3
SLEEP_LENGTH = 5
GCS_BUCKET = 'action-atlas'
GCS_SUBBUCKETS = 'public/gpt/'
IMG_DIR = 'frames_for_gcs'

program_start = time.time()
parser = argparse.ArgumentParser()
parser.add_argument('-b', '--benchmark', type=str, required=True, help='Local path to JSON file generated by `prep_benchmark.py`')
parser.add_argument('-t', '--tmpdir', type=str, required=True, help='Local path to where clips are stored')
parser.add_argument('-o', '--outdir', type=str, required=True, help='Local path to directory where batch JSONL and UUID+Frame-->GCS mapping will be dumped')
parser.add_argument('-n', '--batchname', type=str, required=True, help='Name of batch; will be stored in OpenAI Batch metadata')
parser.add_argument('-k', type=int, required=True, help='Number of in-context examples being provided. Must be 0, 1, 2, or 3.')
parser.add_argument('--threads', type=int, required=False, default=8, help='Number of threads used to prepare benchmark. No rate limits apply so this can be rather high.')
parser.add_argument('--cache', type=str, required=False, help='Local path to JSON file mapping UUID+Frame --> GCS url')
parser.add_argument('-m', '--model', type=str, required=False, default='gpt-4.1-2025-04-14', help='Name of OpenAI model to use. Defaults to GPT 4.1.')
parser.add_argument('--fps', type=int, required=False, default=1, help='How many frames to sample from each second of video. Must be a whole number.')
args = parser.parse_args()
bfile, out_dir, tmp_dir, batch_name, k, model, threads, cache = args.benchmark, args.outdir, args.tmpdir, args.batchname, args.k, args.model, args.threads, args.cache
DEFAULT_FPS = args.fps
if not os.path.isfile(bfile): raise Exception('ERROR: provided benchmark file could not be located.')
if not os.path.isdir(tmp_dir): raise Exception('ERROR: tmpdir must exist already and be populated with videos.')
if k not in set([0, 1, 2, 3]): raise Exception('ERROR: argument supplied via `-k` must be 0, 1, 2, or 3.')
k_dict = {0: '', 1: 'video shows', 2: 'two videos show', 3: 'three videos show'}
k_text = k_dict[k]

# load in benchmark
with open(bfile, 'r') as f:
    benchmark = json.load(f)
action_ids = list(benchmark.keys())
random.shuffle(action_ids)              # reduces file collisions (two threads uploading same file to GCS at same time) since similar action IDs are usually close to each other

# get api key
api_file = os.environ.get("OPENAI_API", "/gscratch/raivn/tanush/credentials/openai.txt")
try:
    with open(api_file, 'r') as f:
        api_key = f.read().strip()
except Exception as e:
    print("ERROR: unable to read OpenAI API Key at ", api_file)
    raise e
client = OpenAI(api_key=api_key)

# UUIDs to paths
def uuids_to_paths(uuids: list[str]) -> list[str]:
    res = []
    for u in uuids:
        mp4 = os.path.join(tmp_dir, u + '.mp4')
        webm = os.path.join(tmp_dir, u + '.webm')
        if os.path.isfile(mp4):
            res.append(mp4)
        elif os.path.isfile(webm):
            res.append(webm)
        else:
            raise Exception(f"Unable to locate file with webm or mp4 extension at {os.path.join(tmp_dir, u)}")
    return res

# utility to process video
def extract_frames(vid_paths: list[str]) -> list[tuple[list[str], float]]:
    """
    Extracts 2-tuple of frames (as list) and FPS (as float) from the videos located at `vid_paths` using OpenCV.
    """
    def extract(vid_path) -> tuple[list[str], float]:
        video = cv2.VideoCapture(vid_path)
        fps = video.get(cv2.CAP_PROP_FPS)
        b64_frames = []
        while video.isOpened():
            success, frame = video.read()
            if not success: break
            _, buffer = cv2.imencode(".jpg", frame)
            b64_frames.append(base64.b64encode(buffer).decode('utf-8'))
        video.release()
        return (b64_frames, fps)

    results: list[tuple[list[str], float]] = []
    with ThreadPoolExecutor(max_workers=2) as executor:
        results = list(executor.map(extract, vid_paths))
    return results

# initialize Google Cloud Storage client
frames_to_urls: dict[str, str] = {}
frames_lock = threading.Lock()
storage_client = storage.Client()
bucket = storage_client.bucket(GCS_BUCKET)
os.makedirs(IMG_DIR, exist_ok=True)

# optionally load in cached GCS URLs
if cache:
    try:
        with open(cache, 'r') as f:
            frames_to_urls = json.load(f)
    except Exception as e:
        print(f'ERROR: Unable to load in cache at {cache} due to: {e}')
        exit(1)

# utility to get GCS URL of a frame
def frame_to_url(uuid: str, b64_frame: str, frame_idx: int) -> str:
    # if image was already uploaded during *this* session, use that
    with frames_lock:
        url = frames_to_urls.get(f'{uuid}@{frame_idx}', None)
    if url:
        return url
    
    # if image already exists on GCS, use that
    frame_filename = f'{uuid}@{frame_idx}.jpg'
    new_blob_path = os.path.join(GCS_SUBBUCKETS, frame_filename)
    blob = bucket.blob(new_blob_path)
    blob_public_url = os.path.join('https://storage.googleapis.com/', GCS_BUCKET, new_blob_path) 
    if blob.exists():
        with frames_lock:
            frames_to_urls[f'{uuid}@{frame_idx}'] = blob_public_url
        return blob_public_url
    
    # if image has already been saved locally, re-upload that; otherwise, save it and then upload it
    frame_filepath = os.path.join(IMG_DIR, frame_filename)
    if not os.path.isfile(frame_filepath):
        img_data: bytes = base64.b64decode(b64_frame)
        with open(frame_filepath, 'wb') as f:
            f.write(img_data)
    blob.upload_from_filename(frame_filepath)
    blob.make_public()
    
    with frames_lock:
        frames_to_urls[f'{uuid}@{frame_idx}'] = blob_public_url
    return blob_public_url

# utility to transform a series of HTTPS URLs to an OpenAI prompt element
def frames_to_inputs(idx: int, frame_urls: list[str]) -> list:
    return [{"type": "input_text", "text": (f"Frames from Video #{idx}:")}] + [{"type": "input_image", "image_url": frame_url} for frame_url in frame_urls]

# utility to sample frames
def sample_relevant_frames(rel_uuid: str, vid_label: int, all_frames: list[str], sampling_rate: int) -> list:
    """
    Samples every `sampling_rate` frames from video whose frames are `all_frames` and whose UUID is `rel_uuid`.
    Uploads to GCS and returns prompt content for Video #n where n is `vid_label`.
    """
    rel_frames = all_frames[:: sampling_rate]
    rel_indices = [f'{rel_uuid}@{frame_idx}' for frame_idx in np.arange(0, len(all_frames), sampling_rate)]
    rel_urls = [frame_to_url(rel_uuid, rel_frm, rel_idx) for rel_frm, rel_idx in zip(rel_frames, rel_indices)]
    return frames_to_inputs(vid_label, rel_urls)

# given relevant info for this question, creates a proper prompt for it
def prepare_prompts(in_context_content: list, clip_content: list, a_aan, action, s_aan, subdomain, domain):
    if k > 0:
        prompt = {
            "role": "user",
            "content": [
                {
                    "type": "input_text",
                    "text": (
                        f"The following {k_text} {a_aan} {action}, which is {s_aan} {subdomain} in {domain}."
                    )
                },
                *in_context_content,
                # {
                #     "type": "input_text",
                #     "text": f"Recall that {a_aan} {action} is defined as follows: {definition}\n"
                # },
                {
                    "type": "input_text",
                    "text": f"Now consider the following video. Is it also {a_aan} {action}? Please reason through your answer. It is critical that you output 'yes' or 'no' on the final line of your answer."
                },
                *clip_content
            ]
        }
    else:
        prompt = {
            "role": "user",
            "content": [
                {
                    "type": "input_text",
                    "text": (
                        #  Further recall that {a_aan} {action} is defined as follows: {definition}\n 
                        f"Recall that {a_aan} {action} is {s_aan} {subdomain} in {domain}. Does the following video show {a_aan} {action}? Please reason through your answer. It is critical that you output 'yes' or 'no' on the final line of your answer."
                    )
                },
                *clip_content
            ]
        }
    
    return prompt

# shared states
gpt_requests: list[dict] = []
errors: list[str] = []
requests_lock = threading.Lock()
errors_lock = threading.Lock()

# core benchmark logic
def process_id(action_id: str):
    tmp = benchmark[action_id]
    action, domain, subdomain = tmp['action'], tmp['domain'], tmp['subdomain']
    subdomain = tmp['subdomain'] if tmp['subdomain'] and tmp['subdomain'] != 'NULL' else 'action'
    a_aan = 'an' if action[0].lower() in set(['a', 'i', 'o', 'u', 'e']) else 'a'
    s_aan = 'an' if subdomain[0].lower() in set(['a', 'i', 'o', 'u', 'e']) else 'a'
    out = {}
    
    # gather in-context examples
    in_context: list[str] = tmp['in_context']
    num_ic = len(in_context)
    in_context_paths: list[str] = uuids_to_paths(in_context)
    ic_info = extract_frames(in_context_paths)
    total_ic_seconds: int = sum([math.ceil(len(ic_info[i][0]) / ic_info[i][1]) for i in range(len(in_context))])
        
    def prep_request(uuids: list[str], is_positive: bool):
        paths: list[str] = uuids_to_paths(uuids)
        tc_info = extract_frames(paths)
        seconds: list[int] = [math.ceil(len(tc_info[i][0]) / tc_info[i][1]) for i in range(len(uuids))]
        out: list[dict] = []

        for i in range(len(uuids)):
            total_seconds = total_ic_seconds + seconds[i]
            if total_seconds * DEFAULT_FPS <= MAX_FRAMES:
                clip_content = sample_relevant_frames(uuids[i], num_ic + 1, tc_info[i][0], math.ceil(tc_info[i][1]) // DEFAULT_FPS)
                in_context_content = []
                for j, icf in enumerate(ic_info):
                    content = sample_relevant_frames(in_context[j], j + 1, icf[0], math.ceil(icf[1]) // DEFAULT_FPS)
                    in_context_content.extend(content)
            else:
                frames_per_video = MAX_FRAMES // (num_ic + 1)
                clip_sample_rate = max(1, len(tc_info[i][0]) // frames_per_video)
                clip_content = sample_relevant_frames(uuids[i], num_ic + 1, tc_info[i][0], clip_sample_rate)
                in_context_content = []
                for j, icf in enumerate(ic_info):
                    ic_sample_rate = max(1, len(icf[0]) // frames_per_video)
                    content = sample_relevant_frames(in_context[j], j + 1, icf[0], ic_sample_rate)
                    in_context_content.extend(content)
            
            prompt = prepare_prompts(in_context_content, clip_content, a_aan, action, s_aan, subdomain, domain)
            out.append({
                "custom_id": f"{action_id}-{'pos' if is_positive else 'neg'}-{i+1}",
                "method": "POST",
                "url": "/v1/responses",
                "body": {
                    "model": model,
                    "input": [prompt],
                    "max_output_tokens": 10000,
                    "temperature": 0
                }
            })
        
        with requests_lock:
            gpt_requests.extend(out)
            
    positives: list[str] = tmp['positives']
    negatives: list[str] = [n['uuid'] for n in tmp['negatives']]
    try:
        prep_request(positives, is_positive=True)
        prep_request(negatives, is_positive=False)
    except Exception as e:
        err = f"EXCEPTION: unable to prep benchmark for action id {action_id} because: " + str(e)
        print(err)
        with errors_lock:
            errors.append(err)
                
# parallelize the benchmark logic
with ThreadPoolExecutor(max_workers=threads) as executor:
    futures = [executor.submit(process_id, action_id) for action_id in action_ids]
    for _ in tqdm(as_completed(futures), total=len(futures), desc="prepping benchmark"):
        pass

# Write batch JSONL
os.makedirs(out_dir, exist_ok=True)
out_file = os.path.join(out_dir, 'batchin.jsonl')
with open(out_file, 'w') as f:
    for req in gpt_requests:
        json.dump(req, f)
        f.write('\n')
mapping_file = os.path.join(out_dir, 'gcs_cache.json')
with open(mapping_file, 'w') as f:
    json.dump(frames_to_urls, f)